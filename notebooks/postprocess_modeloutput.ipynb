{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a48de523",
   "metadata": {},
   "source": [
    "# Postprocessing\n",
    "\n",
    "This notebook contains the postprocessing workflow for the shallow-water simulations generated by `scripts/simulation.jl`.  \n",
    "Its purpose is to extract dynamically relevant diagnostics from the raw model output and to prepare fields for analysis and visualization used in the associated study.\n",
    "\n",
    "Input–output utilities (loading model output, metadata, and derived fields) are implemented in `utils/io.py`.  \n",
    "Methods for interpolating simulation fields onto\n",
    "- constant-$H$ (depth-following) contours, and\n",
    "- constant-$y$ (straight cross-slope transects)\n",
    "\n",
    "are provided in `utils/grid.py`.\n",
    "\n",
    "The focus of this notebook is on computing and organizing these postprocessed quantities in a reproducible way.  \n",
    "Final figures and publication-ready visualizations based on this output are produced in the companion notebook `make_figures.ipynb`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b5ecdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# Set up project root for imports\n",
    "project_root = Path.cwd().parents[0]\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Custom utilities\n",
    "from utils.config import load_config\n",
    "from utils.io import read_raw_output, ensure_dir\n",
    "from utils.grid import prepare_dsH, interp_ds, mean_onH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02898e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output folder for postprocessed data\n",
    "output_folder = str(project_root)+\"/output/processed/\"\n",
    "\n",
    "\n",
    "# Focus depth contour. Used for plotting and analysis. \n",
    "# This correspond to the mid-depth contour\n",
    "focus_j = 45\n",
    "\n",
    "\n",
    "# subregion for analysis\n",
    "analysis_region = {\n",
    "    # short forcing period\n",
    "    \"short\": {\n",
    "        \"focus_time_start\" : -(128+8)*8,\n",
    "        \"focus_time_end\"   : -8*8,\n",
    "        \"focus_j_start\": 20,\n",
    "        \"focus_j_end\": 70,\n",
    "    },\n",
    "    # long forcing period\n",
    "    \"long\": {\n",
    "        \"focus_time_start\" : -(128+64)*8,\n",
    "        \"focus_time_end\"   : -64*8,\n",
    "        \"focus_j_start\": 20,\n",
    "        \"focus_j_end\": 70,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def calculate_analytical_estimates_xr(ds,forcing_vars,params):\n",
    "    \"\"\"\n",
    "    Analytical estimate of the response y to forcing F with exponential decay time scale H(j)/R. \n",
    "    F can be either a single variable or a sum of multiple variables. \n",
    "    So either just surface stress, or surface stress + relative vorticity forcing, etc.\n",
    "    The analytical solution is computed as a discrete convolution in time:\n",
    "    \n",
    "    y(t_j) = ∫_0^{t_j} exp[-(R/H(j)) * (t_j - τ)] * F(τ, j) dτ\n",
    "    \n",
    "    Arguments:\n",
    "    - ds: xarray.Dataset with model output data interpolated to H contours. Must contain \"depth\" and \"time\" dimensions.\n",
    "    - forcing_vars: list of variable names in ds to sum as forcing F.\n",
    "    - params: dictionary with model parameters, must include \"R\" and \"outputtime\".  \n",
    "    \n",
    "    Returns:\n",
    "    - y: xarray.DataArray with the analytical estimate of the response,\n",
    "         with same dimensions as the summed forcing F.\n",
    "\n",
    "    \"\"\"\n",
    "    R = float(params[\"R\"])\n",
    "    dt = float(params[\"outputtime\"]) \n",
    "\n",
    "    H = ds[\"depth\"]  \n",
    "    \n",
    "    # Sum forcing fields (must have dims include \"time\" and \"j\")\n",
    "    F = sum(ds[v] for v in forcing_vars)\n",
    "\n",
    "    t = ds[\"time\"]\n",
    "    nT = t.sizes[\"time\"]\n",
    "    if nT == 0:\n",
    "        raise ValueError(\"Empty time axis.\")\n",
    "    if nT == 1:\n",
    "        return xr.zeros_like(F)\n",
    "\n",
    "    # k(j) = R/H(j), broadcast over all non-time dims of F\n",
    "    k = (R / H).broadcast_like(F.isel(time=0))\n",
    "\n",
    "    # Precompute coefficients (constant in time)\n",
    "    decay = np.exp(-k * dt)\n",
    "    # Safe alpha for k≈0: limit -> dt\n",
    "    alpha = xr.where(np.abs(k) > 0, (1.0 - decay) / k, dt)\n",
    "\n",
    "    # build y \n",
    "    y0 = xr.zeros_like(F.isel(time=0, drop=True))\n",
    "    ys = [y0]\n",
    "    for i in range(1, nT):\n",
    "        Fi_1 = F.isel(time=i - 1, drop=True)  # drop time here too\n",
    "        y_next = decay * ys[-1] + alpha * Fi_1\n",
    "        ys.append(y_next)\n",
    "    y = xr.concat(ys, dim=\"time\").assign_coords(time=t) / H\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23251fb9",
   "metadata": {},
   "source": [
    "## Focus cases\n",
    "\n",
    "We begin by postprocessing the *focus cases*: shallow-water simulations forced by spatially uniform along-slope wind stress over a corrugated slope bathymetry. Two forcing periods are considered:\n",
    "- a long-period case (128 days), and\n",
    "- a short-period case (16 days).\n",
    "\n",
    "These two cases are intended to highlight differences in the dynamical response across forcing timescales.\n",
    "\n",
    "For each case, the workflow consists of two complementary parts:\n",
    "\n",
    "1. **Depth-following (constant-$H$) diagnostics**, used to evaluate circulation and momentum balances along topographically steered flow paths. In this framework, circulation is averaged along depth contours, and momentum terms are expressed in a contour-integrated form consistent with the theoretical framework used in the paper. Time series at a representative mid-slope contour are extracted and compared to linear and nonlinear analytical estimates.\n",
    "\n",
    "2. **Cartesian (constant-$y$) diagnostics**, used to compute momentum terms on straight along-slope transects. These diagnostics provide access to terms such as topographic form stress and momentum flux convergence, which are not explicitly present in the depth-following formulation but are useful for interpretation and comparison.\n",
    "\n",
    "For each case, we:\n",
    "- interpolate the raw model output to the required coordinate system,\n",
    "- compute the relevant momentum terms,\n",
    "- restrict the analysis to a dynamically equilibrated focus period, and\n",
    "- save compact NetCDF files containing only the quantities needed for subsequent analysis and figure generation.\n",
    "\n",
    "The loop below implements this workflow for the long- and short-period forcing cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad64a70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration from ../configs/baseline_forcing/long.json\n",
      "Loading configuration from ../configs/baseline_forcing/short.json\n"
     ]
    }
   ],
   "source": [
    "for case in [\"long\", \"short\"]:\n",
    "    # load data\n",
    "    params = load_config(f\"../configs/baseline_forcing/{case}.json\")\n",
    "    ds = read_raw_output(params)\n",
    "    \n",
    "\n",
    "    #####################################################\n",
    "    #### DEPTH-FOLLOWING INTERPOLATION AND DIAGNOSES ####\n",
    "    #####################################################\n",
    "    \n",
    "    ### interpolate to depth-following grid ###\n",
    "    # determine target depths H_targets (mean depth along xC at each yC)\n",
    "    H_targets = ds.bath.mean(\"xC\").values\n",
    "    \n",
    "    dsH = prepare_dsH(ds, params, H_targets)\n",
    "    \n",
    "    ### calculate circulation ###\n",
    "    dsH[\"circulation\"] = mean_onH(dsH, variable=\"ui\")\n",
    "        \n",
    "    ### calculate momentum terms ###\n",
    "    dsH[\"BS\"] = -dsH.circulation*params[\"R\"]                       # Bottom stress\n",
    "    dsH[\"RVF\"] = mean_onH(dsH, variable=\"zetaflux\") * dsH.depth    # Relative vorticity flux\n",
    "    dsH[\"SS\"] = mean_onH(dsH, variable=\"forcing_i\")                # Surface stress\n",
    "\n",
    "    ### timeseries at focus depth contour ###\n",
    "    \n",
    "    # circulation estimates\n",
    "    dsH[\"linear_estimate\"] = calculate_analytical_estimates_xr(dsH, [\"SS\"], params)\n",
    "    dsH[\"nonlinear_estimate\"] = calculate_analytical_estimates_xr(dsH, [\"SS\", \"RVF\"], params)\n",
    "    \n",
    "    ts = xr.Dataset()\n",
    "    ts[\"circulation\"] = dsH[\"circulation\"].isel(j=focus_j)\n",
    "    ts[\"linear_estimate\"] = dsH[\"linear_estimate\"].isel(j=focus_j)\n",
    "    ts[\"nonlinear_estimate\"] = dsH[\"nonlinear_estimate\"].isel(j=focus_j)\n",
    "    \n",
    "    # select focus period\n",
    "    ts = ts.isel(\n",
    "        time=slice(\n",
    "            analysis_region[case][\"focus_time_start\"],\n",
    "            analysis_region[case][\"focus_time_end\"],\n",
    "        ),\n",
    "    )\n",
    "    ts[\"time\"] = ts[\"time\"] - ts[\"time\"].values[0]\n",
    "    \n",
    "    ensure_dir(output_folder+\"/timeseries/\")\n",
    "    ts.squeeze().to_netcdf(output_folder+f\"/timeseries/analytical_estimates_{case}.nc\")\n",
    "    \n",
    "    \n",
    "    # select focus region and period\n",
    "    dsH = dsH.isel(\n",
    "        time=slice(\n",
    "            analysis_region[case][\"focus_time_start\"],\n",
    "            analysis_region[case][\"focus_time_end\"],\n",
    "        ),\n",
    "        j=slice(\n",
    "            analysis_region[case][\"focus_j_start\"],\n",
    "            analysis_region[case][\"focus_j_end\"],\n",
    "        ),\n",
    "    )\n",
    "    dsH[\"time\"] = dsH[\"time\"] - dsH[\"time\"].values[0]  # reset time to start at 0\n",
    "    \n",
    "    \n",
    "    ### save relevant momentum terms ###\n",
    "    if case == \"short\":\n",
    "        dsH = dsH.isel(time=slice(-16*8-1, None))  # only last 16 days for short case\n",
    "        dsH[\"time\"] = dsH[\"time\"] - dsH[\"time\"].values[0]  # reset time to start at 0\n",
    "        \n",
    "    ensure_dir(output_folder+\"/momentum_terms_H/\")\n",
    "    dsH[[\"circulation\", \"RVF\", \"BS\", \"SS\"]].to_netcdf(\n",
    "        output_folder+f\"/momentum_terms_H/momentum_terms_H_{case}.nc\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    #####################################################\n",
    "    ############### CARTESIAN DIAGNOSES #################\n",
    "    #####################################################\n",
    "    \n",
    "    dsY = interp_ds(ds, params, [\"u\", \"v\", \"zetav\",\"forcing_x\", \"detadx\", \"duvhdy\"])\n",
    "    dsY = dsY.isel(\n",
    "        time=slice(\n",
    "            analysis_region[case][\"focus_time_start\"],\n",
    "            analysis_region[case][\"focus_time_end\"],\n",
    "        ),\n",
    "        yC=slice(\n",
    "            analysis_region[case][\"focus_j_start\"],\n",
    "            analysis_region[case][\"focus_j_end\"],\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    if case == \"short\":\n",
    "        dsY = dsY.isel(time=slice(-16*8, None))  # only last 16 days for short case   \n",
    "    \n",
    "    dsY[\"time\"] = dsY[\"time\"] - dsY[\"time\"].values[0]  # reset time to start at 0\n",
    "\n",
    "    # calculate circulation\n",
    "    dsY[\"circulation\"] = dsY.u.mean(\"xC\")\n",
    "\n",
    "    # calculate momentum terms\n",
    "    H0 = dsY.bath.mean(\"xC\")\n",
    "    h = H0 - dsY.bath \n",
    "\n",
    "    dsY[\"BS\"] = -dsY.circulation*params[\"R\"]                       # Bottom stress\n",
    "    dsY[\"TFS\"] = (-params[\"gravitational_acceleration\"]*dsY.detadx*dsY.bath).mean(\"xC\")  # Topographic form stress\n",
    "    dsY[\"MFC\"] = (-dsY.duvhdy).mean(\"xC\")                          # Momentum flux convergence\n",
    "    dsY[\"SS\"] = (dsY.forcing_x).mean(\"xC\")                         # Surface stress\n",
    "    dsY[\"QGPVF\"] = (dsY.zetav).mean(\"xC\")*H0 + (dsY.v*h).mean(\"xC\")*params[\"f\"]          # Quasi-geostrophic potential vorticity flux\n",
    "    \n",
    "    \n",
    "    # save relevant momentum terms\n",
    "    ensure_dir(output_folder+\"/momentum_terms_y/\")\n",
    "    dsY[[\"circulation\", \"BS\",\"TFS\", \"MFC\", \"SS\", \"QGPVF\"]].to_netcdf(\n",
    "        output_folder+f\"/momentum_terms_y/momentum_terms_y_{case}.nc\"\n",
    "    )   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f50798",
   "metadata": {},
   "source": [
    "## Contrasting cases without corrugations\n",
    "\n",
    "Next we analyze a set of contrasting simulations with a *smooth* slope (no corrugations).  \n",
    "These cases are used as a baseline to isolate the role of corrugation-driven flow–topography interactions in the focus cases.\n",
    "\n",
    "We consider four simulations:\n",
    "- `long_nobumps` and `short_nobumps`: long-/short-period forcing with *along-slope* wind stress only (same periods as the focus cases),\n",
    "- `long_nobumps_crosswind` and `short_nobumps_crosswind`: the same, but with an additional cross-slope wind-stress component.\n",
    "\n",
    "All four cases are analyzed in **Cartesian (constant-$y$) coordinates**, since the smooth slope does not require depth-following interpolation for our diagnostics. For each case we:\n",
    "1. interpolate the raw model output to the analysis grid (`dsY`),\n",
    "2. restrict the dataset to the same focus time window and cross-slope region as used previously (based on `long`/`short`),\n",
    "3. compute along-slope circulation and the associated momentum terms (surface stress, bottom stress, momentum flux convergence, and topographic form stress),\n",
    "4. save both:\n",
    "   - **time-mean cross-slope structure** (terms averaged over time, stored as `*y`), and\n",
    "   - **time series of domain-mean terms** (terms averaged over `y`, stored as `*t`),\n",
    "\n",
    "to compact NetCDF files for plotting and comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65c6458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration from ../configs/baseline_forcing/long_nobumps.json\n",
      "Loading configuration from ../configs/baseline_forcing/short_nobumps.json\n",
      "Loading configuration from ../configs/baseline_forcing/long_nobumps_crosswind.json\n",
      "Loading configuration from ../configs/baseline_forcing/short_nobumps_crosswind.json\n"
     ]
    }
   ],
   "source": [
    "for case in [\"long_nobumps\", \"short_nobumps\", \"long_nobumps_crosswind\", \"short_nobumps_crosswind\"]:\n",
    "    # load data\n",
    "    params = load_config(f\"../configs/baseline_forcing/{case}.json\")\n",
    "    ds = read_raw_output(params)\n",
    "    \n",
    "\n",
    "\n",
    "    dsY = interp_ds(ds, params, [\"u\", \"v\", \"zetav\",\"forcing_x\", \"detadx\", \"duvhdy\"])\n",
    "    dsY = dsY.isel(\n",
    "        time=slice(\n",
    "            analysis_region[case.split(\"_\")[0]][\"focus_time_start\"],\n",
    "            analysis_region[case.split(\"_\")[0]][\"focus_time_end\"],\n",
    "        ),\n",
    "        yC=slice(\n",
    "            analysis_region[case.split(\"_\")[0]][\"focus_j_start\"],\n",
    "            analysis_region[case.split(\"_\")[0]][\"focus_j_end\"],\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    if case.split(\"_\")[0] == \"short\":\n",
    "        dsY = dsY.isel(time=slice(-16*8, None))  # only last 16 days for short case   \n",
    "    \n",
    "    dsY[\"time\"] = dsY[\"time\"] - dsY[\"time\"].values[0]  # reset time to start at 0\n",
    "\n",
    "\n",
    "\n",
    "    dsY[\"circulation\"] = dsY.u.mean(\"xC\")\n",
    "    dsY[\"TFS\"] = (-params[\"gravitational_acceleration\"]*dsY.detadx*dsY.bath).mean(\"xC\")\n",
    "    dsY[\"MFC\"] = (-dsY.duvhdy).mean(\"xC\")\n",
    "    dsY[\"SS\"] = (dsY.forcing_x).mean(\"xC\")\n",
    "    dsY[\"BS\"] = -dsY.circulation*params[\"R\"]\n",
    "    \n",
    "    # time-mean terms\n",
    "    dsY[\"TFSy\"] = dsY[\"TFS\"].mean(\"time\")\n",
    "    dsY[\"MFCy\"] = dsY[\"MFC\"].mean(\"time\")\n",
    "    dsY[\"SSy\"] = dsY[\"SS\"].mean(\"time\")\n",
    "    dsY[\"BSy\"] = dsY[\"BS\"].mean(\"time\")\n",
    "    \n",
    "    # y meaned terms\n",
    "    dsY[\"TFSt\"] = dsY[\"TFS\"].mean(\"yC\")\n",
    "    dsY[\"MFCt\"] = dsY[\"MFC\"].mean(\"yC\")\n",
    "    dsY[\"SSt\"] = dsY[\"SS\"].mean(\"yC\")\n",
    "    dsY[\"BSt\"] = dsY[\"BS\"].mean(\"yC\")\n",
    "    \n",
    "    # save relevant momentum terms\n",
    "    ensure_dir(output_folder+\"/momentum_terms_y/\")\n",
    "    dsY[[\"circulation\", \"TFSt\", \"MFCt\", \"SSt\", \"BSt\",\"TFSy\", \"MFCy\", \"SSy\", \"BSy\"]].to_netcdf(\n",
    "        output_folder+f\"/momentum_terms_y/momentum_terms_y_{case}.nc\"\n",
    "    )   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c31ddf",
   "metadata": {},
   "source": [
    "## Wave-based diagnostics\n",
    "\n",
    "In this section, we compute a set of diagnostics used to compare the simulated circulation response to characteristic properties of topographic waves. \n",
    "\n",
    "The calculations below focus on three related quantities:\n",
    "1. characteristic prograde and retrograde flow speeds inferred from the simulations,\n",
    "2. the cross-slope structure of the dominant wave-like response, and\n",
    "3. the dependence of maximum flow speed on forcing strength across multiple realizations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2a2bdf",
   "metadata": {},
   "source": [
    "### Arrest speed\n",
    "\n",
    "We first estimate characteristic prograde and retrograde flow speeds directly from the simulated circulation along depth-following contours. These speeds are used as empirical measures of the maximum along-slope flow attained in each direction, and are interpreted as proxies for wave arrest speeds.\n",
    "\n",
    "For a given depth contour (or range of contours), we extract the circulation time series and identify:\n",
    "- the maximum prograde circulation attained over the analysis period, and\n",
    "- the maximum retrograde circulation (in magnitude).\n",
    "\n",
    "When `spread=True`, we additionally estimate the range of retrograde speeds across neighboring contours, providing a measure of spatial variability in the arrest behavior.\n",
    "\n",
    "These diagnostics are computed for simulations with different corrugation wavelengths, enabling direct comparison between arrest speeds and topographic length scales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee92314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_prograde_retrograde_speed(dsH,selection=slice(40,50), spread=True):\n",
    "    slope = dsH.sel(j=selection).circulation\n",
    "    #slope = dsH.sel(j=slice(40,50)).circulation    \n",
    "    \n",
    "    if spread:\n",
    "        prograde = slope.max(\"time\").mean(\"j\").item()\n",
    "        retrograde = np.abs(slope.min(\"time\").mean(\"j\").item())\n",
    "        \n",
    "        retrograde_max = np.abs(slope.min(\"time\").min(\"j\").item())\n",
    "        retrograde_min = np.abs(slope.min(\"time\").max(\"j\").item())\n",
    "    \n",
    "    \n",
    "        return retrograde, prograde, retrograde_min, retrograde_max\n",
    "\n",
    "    else:\n",
    "        retrograde = np.abs(np.min(slope))\n",
    "        prograde = np.max(slope)\n",
    "        \n",
    "        return retrograde, prograde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7d14e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration from ../configs/varying_bathymetry/half.json\n",
      "Loading configuration from ../configs/baseline_forcing/long.json\n",
      "Loading configuration from ../configs/varying_bathymetry/double.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params_22km = load_config(\"../configs/varying_bathymetry/half.json\")\n",
    "params_45km = load_config(\"../configs/baseline_forcing/long.json\")\n",
    "params_90km = load_config(\"../configs/varying_bathymetry/double.json\")\n",
    "\n",
    "arrest_speed_results = {}\n",
    "\n",
    "for params, wavelength in zip([params_22km, params_45km, params_90km], [22.5, 45, 90]):\n",
    "    ds = read_raw_output(params)\n",
    "    dsH = prepare_dsH(ds, params, H_targets)\n",
    "    \n",
    "    # diagnose circulation\n",
    "    dsH[\"circulation\"] = mean_onH(dsH, variable=\"ui\")\n",
    "    \n",
    "    retrograde, prograde, retrograde_min, retrograde_max = estimate_prograde_retrograde_speed(dsH)\n",
    "    \n",
    "    arrest_speed_results[wavelength] = {\n",
    "        \"retrograde\": retrograde,\n",
    "        \"prograde\": prograde,\n",
    "        \"retrograde_min\": retrograde_min,\n",
    "        \"retrograde_max\": retrograde_max,\n",
    "    }\n",
    "    \n",
    "ensure_dir(output_folder+\"/wave_comparison/\")\n",
    "json.dump(arrest_speed_results, open(output_folder+\"/wave_comparison/arrest_speeds.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f07df",
   "metadata": {},
   "source": [
    "### Mode structure\n",
    "\n",
    "To examine the spatial structure of the wave-like response, we analyze the cross-slope structure of sea-surface height anomalies during the long-period forcing case.\n",
    "\n",
    "The total height field is decomposed into a mean and an anomaly, and the anomaly is separated into two time intervals corresponding to opposite phases of the forcing. By combining these two phases, we construct a composite field to isolate the wave mode, suppressing the strong topogrpahic influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e934ce46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration from ../configs/baseline_forcing/long.json\n"
     ]
    }
   ],
   "source": [
    "params = load_config(\"../configs/baseline_forcing/long.json\")\n",
    "ds = read_raw_output(params)\n",
    "ds = ds.isel(\n",
    "    time=slice(\n",
    "        analysis_region[\"long\"][\"focus_time_start\"],\n",
    "        analysis_region[\"long\"][\"focus_time_end\"],\n",
    "    ),\n",
    ")\n",
    "ds[\"time\"] = ds[\"time\"] - ds[\"time\"].values[0]  # reset time to start at 0\n",
    "\n",
    "eta = ds[\"h\"] - ds[\"bath\"]\n",
    "etanod = eta - eta.mean(dim=\"xC\")\n",
    "\n",
    "etanod_neg = etanod.isel(time=slice(0,64*8))\n",
    "etanod_pos = etanod.isel(time=slice(64*8,None))\n",
    "etanod_pos[\"time\"] = etanod_pos[\"time\"] - etanod_pos[\"time\"].isel(time=0)\n",
    "\n",
    "mode = etanod_neg + etanod_pos \n",
    "\n",
    "mode.to_netcdf(output_folder+\"/wave_comparison/mode_structure.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1bc5e",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae27e90",
   "metadata": {},
   "source": [
    "### Maximum speed as a function of forcing strength\n",
    "\n",
    "Finally, we examine how the maximum prograde and retrograde circulation scales with forcing amplitude. For a set of simulations spanning a range of wind-stress strengths, we extract the maximum circulation attained at selected depth contours.\n",
    "\n",
    "For each forcing period (short and long), multiple realizations are analyzed. The results are assembled into a tidy dataset containing:\n",
    "- forcing strength,\n",
    "- maximum prograde circulation, and\n",
    "- maximum retrograde circulation,\n",
    "\n",
    "as functions of depth and forcing amplitude.\n",
    "\n",
    "These diagnostics are used to assess whether circulation increases linearly with forcing, or whether nonlinear saturation occurs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cda02579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration from ../configs/varying_forcing/short_001.json\n",
      "Loading configuration from ../configs/varying_forcing/short_002.json\n",
      "Loading configuration from ../configs/varying_forcing/short_003.json\n",
      "Loading configuration from ../configs/varying_forcing/short_004.json\n",
      "Loading configuration from ../configs/varying_forcing/short_005.json\n",
      "Loading configuration from ../configs/varying_forcing/short_006.json\n",
      "Loading configuration from ../configs/varying_forcing/short_007.json\n",
      "Loading configuration from ../configs/varying_forcing/short_008.json\n",
      "Loading configuration from ../configs/varying_forcing/long_001.json\n",
      "Loading configuration from ../configs/varying_forcing/long_002.json\n",
      "Loading configuration from ../configs/varying_forcing/long_003.json\n",
      "Loading configuration from ../configs/varying_forcing/long_004.json\n",
      "Loading configuration from ../configs/varying_forcing/long_005.json\n",
      "Loading configuration from ../configs/varying_forcing/long_006.json\n",
      "Loading configuration from ../configs/varying_forcing/long_007.json\n",
      "Loading configuration from ../configs/varying_forcing/long_008.json\n"
     ]
    }
   ],
   "source": [
    "depths_to_use = [H_targets[40], H_targets[45], H_targets[50]]\n",
    "periods = [\"short\", \"long\"]\n",
    "n_runs = 8 \n",
    "\n",
    "# --- Pre-allocate tidy dataset ---\n",
    "ds_out = xr.Dataset(\n",
    "    coords=dict(\n",
    "        period=(\"period\", periods),\n",
    "        run=(\"run\", np.arange(1, n_runs + 1)),\n",
    "        depth=(\"depth\", depths_to_use),\n",
    "    ),\n",
    "    data_vars=dict(\n",
    "        forcing_strength=((\"period\", \"run\"), np.full((len(periods), n_runs), np.nan)),\n",
    "        prograde_max=((\"period\", \"depth\", \"run\"), np.full((len(periods), len(depths_to_use), n_runs), np.nan)),\n",
    "        retrograde_max=((\"period\", \"depth\", \"run\"), np.full((len(periods), len(depths_to_use), n_runs), np.nan)),\n",
    "    ),\n",
    ")\n",
    "\n",
    "for p_idx, p in enumerate(periods):\n",
    "    for r in range(1, n_runs + 1):\n",
    "        params_i = load_config(f\"../configs/varying_forcing/{p}_{r:03d}.json\")\n",
    "        forcing = params_i[\"tau0\"]\n",
    "        ds_i = read_raw_output(params_i).isel(time=slice(-128*8, None))\n",
    "\n",
    "        dsH_i = prepare_dsH(ds_i, params_i, depths_to_use)\n",
    "        circ = mean_onH(dsH_i, variable=\"ui\")\n",
    "        dsH_i[\"circulation\"] = circ#hanning_filter(circ, window_length=2*8)\n",
    "\n",
    "        ds_out[\"forcing_strength\"][p_idx, r - 1] = forcing\n",
    "\n",
    "        for k, H in enumerate(dsH_i[\"depth\"].values):\n",
    "            retro, pro = estimate_prograde_retrograde_speed(dsH_i, selection=k, spread=False)\n",
    "            ds_out[\"prograde_max\"][p_idx, k, r - 1] = pro\n",
    "            ds_out[\"retrograde_max\"][p_idx, k, r - 1] = retro\n",
    "            \n",
    "ds_sorted = ds_out.copy() \n",
    "for p in periods: \n",
    "    F = ds_out[\"forcing_strength\"].sel(period=p) \n",
    "    order = np.argsort(F.values) \n",
    "    ds_sorted[\"forcing_strength\"].loc[dict(period=p)] = F.values[order] \n",
    "    for var in [\"prograde_max\", \"retrograde_max\"]: \n",
    "        ds_sorted[var].loc[dict(period=p)] = ds_out[var].sel(period=p).values[..., order]\n",
    "        \n",
    "vars_to_save = [\"forcing_strength\", \"prograde_max\", \"retrograde_max\"]\n",
    "ds_to_write = ds_sorted[vars_to_save]\n",
    "\n",
    "ds_to_write.to_netcdf(output_folder+\"/wave_comparison/forcing_vs_arrest_speeds.nc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba9841f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temporal-topo-flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
